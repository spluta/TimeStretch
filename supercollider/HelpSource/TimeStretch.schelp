class:: TimeStretch
summary:: Time Stretch
related:: TimeStretch2, Classes/FFT, Classes/IFFT, Classes/PV_Diffuser, Classes/PV_BrickWall
categories::  UGens>FFT

Description::
TimeStretch is the Cadillac of time stretching algorithms. All calculations and audio processing are done in the language, so it is slow. For a faster version that uses the server, but doesn't sound quite as good, check out TimeStretch2.

Implements a phase randomized FFT time stretch algorithm, the Ness Stretch, which splits the original sound file into 9 discrete frequency bands, and uses a decreasing frame size to correspond to increasing frequency. Starting with a largest frame of 65536, the algorithm will use the following frequency/frame size breakdown:

0-86hz : 65536

86-172hz : 32768

172-344 : 16384

344-689 : 8192

689-1378 : 4096

1378-2756 : 2048

2756 - 5512 : 1024

5512-11025 : 512

11025-22050 : 256

The algorithm also correlates each grain in the FFT with the previous and next grain, and creates a custom crossfade for each grain based on the correlations between grains

classmethods::

method::stretch

Performs the stretch and places temporary files into a temporary folder.

argument::inFile

Path to the input file to be stretch. Can be a mono or stereo file.

argument::outFile

Path to the destination output file. Will create a temporary folder

argument::dur

The duration of the sound file to be stretched. -1 will process the entire file;

argument::durMult

	How many times longer the outFile will be than the inFile. Goes waaaaay past 11 (try 100!).

argument::chanArray

An array that indicates which channels of the inFile to process.

argument:: chunkSize

The program will break the incoming audio into multiple output files, each with chunkSize samples. These files will go into a directory named after the name given to the outFile.

argument:: startChan

Default is 0. This is the index to start on in the channel array.

argument:: startFrame

Default is 0. This is the frame to start processing on. If the process has already made a number of frames, and the processes was interrupted somehow, the process can start in the middle, at any frame that has already written its temporary buffer.

argument:: fft/real fft

Whether to use an (0) FFT or (1) Real-FFT. Real-FFT is default.

method::mergeFiles

argument::server

A server. Will boot if it isn't booted.

argument::folderIn

The folder to look in

argument::numChans

The number of channels to merge into the final audio file.

Examples::

Will start an NRT server, load the file, and execute the time stretch. Each instance of TimeStretch will run on its own server, so you can run as many simultaneously as your computer can handle.

code::

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch("Bieber", "BieberOut", 20, 100, [0,1]); //try it with Biebs

//The new sound file will go into the default recordings directory in SC
TimeStretch.stretch(Platform.resourceDir +/+ "sounds/a11wlk01.wav", Platform.recordingsDir +/+ "a11wlk01_10.wav", -1, 100, [0]);

//merge the files in the temporary folder into one file (requires FluidBufCompose from the FluCoMa library)
TimeStretch.mergeFiles(s, Platform.recordingsDir +/+ "a11wlk01_10_render/", 1)

//If the above throws an error, you may need to increase the default Server memory allocation when using multiple FFT layers. If so, run the following before running the above line of code

::
